# AGL Energy — Zerobus Ignition Gateway Architecture

## Customer Context

AGL Energy operates 2M+ historian tags across coal, gas, hydro, wind, and battery assets.
Their current stack is anchored on AVEVA PI, which introduces:

- **Vendor lock-in**: data trapped in proprietary formats; expensive per-tag licensing.
- **Operational overhead**: separate infrastructure for ingestion (PI Interfaces/Connectors),
  buffer nodes, and archive servers for every new site.
- **New-asset onboarding friction**: each new battery (e.g., Liddell 500 MW, Tomago 500 MW)
  or wind farm (Hexham 600 MW, Pottinger 831 MW) requires standing up PI collectors,
  buffer/relay nodes, and historian servers before a single tag flows.
- **Compression myth**: AVEVA's "swinging door" compression is cited as a unique advantage.
  The Zerobus connector **already implements Swinging Door Trending (SDT) compression at
  the edge/connector layer**, giving identical compression semantics — but writing into open
  Delta tables instead of a proprietary archive.

John (AGL stakeholder) believes a **lakehouse can standardise all asset data into open table
formats** and that current approaches carry too much operational overhead. This demo proves
him right.

## Architecture — Two Main Zones

### Zone 1: Ignition Gateway (On-Premises / Edge)

The Ignition Gateway is the on-premises SCADA platform running at each AGL site.

**Data Sources (two ingestion paths):**

1. **Tag Manager (PLC / OPC-UA)** — industrial tag subscriptions from PLCs, RTUs, and
   OPC-UA servers on the plant network.
2. **HTTP POST `/ingest` (Event Streams mode)** — REST endpoint accepting JSON payloads
   from external producers (e.g., third-party MQTT bridges, custom apps).

Both paths produce **TagEvent** objects that flow into the Zerobus Module.

**Zerobus Module (.modl) — the core connector:**

The Zerobus Module is an Ignition module (`.modl` file) installed in the gateway.
It has three pipeline stages:

1. **OtEventMapper** — converts TagEvents into OTEvent protobuf messages. This is where
   Swinging Door Trending (SDT) compression is applied at the edge, matching AVEVA PI
   compression semantics but writing to open formats.

2. **StoreAndForwardBuffer** — a two-tier buffer providing guaranteed delivery:
   - **Memory Buffer** (primary, fast) — holds events in RAM for normal throughput.
   - **DiskSpool** (overflow) — spills to disk when memory fills, preventing data loss
     during network outages or Databricks backpressure.
   - Uses **high/low watermark** backpressure to switch between tiers.

3. **ZerobusEventSink** — the egress stage containing the ZerobusClient Manager.
   Sends protobuf-encoded events over **gRPC** to the Databricks Zerobus Endpoint.

**Module Configuration & Observability:**
- Config persisted via `ConfigModel` + `PersistentRecord` in the Ignition Gateway DB.
- REST API at `/system/zerobus/{health, diagnostics, config, ...}` for monitoring.

### Zone 2: Databricks (Cloud Lakehouse)

The Databricks side receives events over **TLS/gRPC** and processes them through a
Spark Declarative Pipeline (SDP) into a medallion architecture, with a Databricks App
serving analytics to users.

#### SDP Pipeline (Lakeflow Declarative)

1. **Zerobus Endpoint** — cloud-side gRPC receiver that accepts the protobuf stream.

2. **Bronze Layer** (`agl_demo.ot.raw_tags`) — raw tag events land as-is in a
   streaming Delta table. Schema-on-read, append-only, full fidelity.

3. **Silver Layer** (`agl_demo.ot.aggregated_tags`) — `bronze_silver.py` reads the
   Bronze streaming table and applies **1-minute tumbling window** aggregations.
   Deduplication, type casting, tag metadata joins.

4. **Analytics / Gold Layer** — multiple materialized views built on Silver:
   - **Health Scores** (`agl_demo.analytics.health_scores`) — `silver_analytics.py`
     computes **z-score anomaly detection** (σ = 2.0 threshold) per asset. Health
     score = 1 − (anomalous / total). Pure Python stats, no ML frameworks.
   - **NEM Prices** (`agl_demo.market.nem_prices`) — synthetic NEM spot price
     generator via `market.py` (lightweight, no external API calls).
   - **Price Forecast** (`agl_demo.market.price_forecast`) — 48-hour ahead forecast
     with guaranteed price spikes, generated by `market.py` diurnal pattern + random.
   - **Revenue Risk** (`agl_demo.analytics.revenue_risk`) — `revenue_risk.py` joins
     health_scores + price_forecast + asset metadata. Formula:
     `capacity × hours × price × (1 − health_score)`. Includes rule-based action
     recommendations ("Monitor", "Schedule inspection", "Urgent maintenance",
     "Critical shutdown").

#### Databricks App (FastAPI)

A Databricks App serves the analytics via REST endpoints:
- `/api/health-scores` → queries `agl_demo.analytics.health_scores`
- `/api/price-forecast` → queries `agl_demo.market.price_forecast`
- `/api/revenue-risk` → queries `agl_demo.analytics.revenue_risk`

All queries are parameterised Databricks SQL. The app provides an operational
dashboard for AGL asset operators and energy traders.

## Key Technical Details

- **Protocol**: gRPC with TLS encryption between gateway and cloud.
- **Serialisation**: Protocol Buffers (protobuf) for compact, schema-evolved payloads.
- **Compression**: SDT (Swinging Door Trending) applied at the OtEventMapper stage —
  same algorithm as AVEVA PI, proving no loss of fidelity.
- **Resilience**: Store-and-forward with disk spill means zero data loss during
  network partitions or cloud maintenance windows.
- **Backpressure**: High/low watermark mechanism prevents OOM while maintaining throughput.
- **Storage**: All layers use Delta Lake — open format, ACID transactions, time travel,
  schema evolution.
- **Pipeline**: Spark Declarative Pipelines (SDP/Lakeflow) for streaming Bronze → Silver
  and materialized views for Gold analytics.
- **ML**: Lightweight — z-score anomaly detection, arithmetic revenue formulas,
  rule-based action thresholds. No heavy ML frameworks required.

## Verified Data Flow (End-to-End)

```
IGNITION GATEWAY                  SDP PIPELINE                        APP
─────────────────                 ────────────                        ───

TagSubscriptionSvc ──gRPC/TLS──► raw_tags (Bronze)
  + HTTP /ingest                      │ readStream
                                      ▼
                                aggregated_tags (Silver)
                                      │ z-score computation
                                      ▼
                                health_scores (MV) ──────► /api/health-scores
                                      │
                                      │ JOIN
market.py (synthetic NEM) ──────► price_forecast (MV) ──► /api/price-forecast
                                      │
                                      │ JOIN (capacity × hours × price × prob)
                                      ▼
                                revenue_risk (MV) ───────► /api/revenue-risk
                                      │
                                      ▼
                                Action recommendations
                                - "Monitor - no action"
                                - "Schedule inspection"
                                - "Urgent maintenance"
                                - "Critical shutdown"
```

## Diagram Requirements

- Show the **Ignition Gateway** as a large outer container (on-premises/edge zone).
- Show the **Zerobus Module** as a nested container inside the gateway with the three
  pipeline stages (OtEventMapper → StoreAndForwardBuffer → ZerobusEventSink).
- Show the **two ingestion paths** entering the module (Tag Manager and HTTP POST).
- Show the **gRPC/TLS connection** crossing from on-prem to cloud.
- Show the **Databricks** zone with:
  - The Zerobus Endpoint receiving the stream.
  - The **SDP pipeline** flowing through Bronze → Silver → Gold/Analytics.
  - **Materialized views** for health scores, price forecast, and revenue risk,
    showing the joins between them.
  - A **Databricks App** box consuming the analytics tables via SQL.
- Show the **NEM market data** as a secondary input feeding into the Gold layer.
- Use the **AGL Energy logo** prominently (top-left or header).
- Use the **Databricks logo** in the cloud zone.
- Use the **Delta Lake logo** near the medallion layers.
- Clearly label the store-and-forward buffer's two tiers (Memory + DiskSpool).
- Show data flow direction with arrows throughout.
- The diagram should convey: **simple, open, resilient — replacing complex proprietary
  infrastructure with a single module, open lakehouse storage, and real-time analytics.**
- Include the **action recommendations** output at the bottom as the business outcome
  ("Monitor" → "Critical shutdown" severity ladder).
