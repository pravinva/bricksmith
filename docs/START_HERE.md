# ğŸš€ Start Here: DSPy Batch Refinement with MCP Integration

## What You Have

You asked: "Why can't DSPy work with my MCP server?"

**Answer:** It can! But you need to understand you have **two different MCP servers**:

1. **Databricks Docs MCP** (Docker) - For documentation searches âœ… Already running
2. **DSPy Proxy MCP** (New) - For batch API proxying â• Need to start this

**Read first:** [`TWO_MCP_SERVERS_EXPLAINED.md`](TWO_MCP_SERVERS_EXPLAINED.md) for a clear explanation.

---

## ğŸ¯ Your Goal

Process 200 AGL RFP responses through DSPy while routing all API calls through your local MCP server for visibility and control.

---

## âš¡ Quick Start (3 Steps)

### Step 1: Start DSPy Proxy MCP Server

```bash
cd /Users/david.okeeffe/databricks-sandbox/nano_banana

# Easy way (recommended)
./start-dspy-proxy.sh

# Or manually
python local_mcp_server.py
```

You should see:
```
ğŸš€ Starting DSPy MCP Server
Server will run on: http://0.0.0.0:8001
```

**Keep this terminal open!**

### Step 2: Expose to Databricks (New Terminal)

```bash
# Install ngrok if needed
brew install ngrok

# Expose port 8001
ngrok http 8001

# Copy the HTTPS URL
# Example: https://abc123.ngrok.io
```

**Keep this terminal open too!**

### Step 3: Run Batch Refinement in Databricks

1. Open `agl_rfp_dspy_with_mcp.py` in Databricks
2. Update the MCP server URL:
   ```python
   MCP_SERVER_URL = "https://abc123.ngrok.io"  # Your ngrok URL
   ```
3. Set batch mode:
   ```python
   BATCH_MODE = "DEMO"  # Test with 5 responses first
   ```
4. Run all cells

**Watch your MCP server terminal** - you'll see all DSPy requests flowing through! ğŸ‰

---

## ğŸ“Š What You'll See

### In Your MCP Server Terminal:

```
================================================================================
ğŸ“¥ REQUEST abc12345
   Endpoint: databricks-claude-sonnet-4-5
   Messages: 1
   Prompt length: 1542 characters
   Max tokens: 2000
   Temperature: 0.1
ğŸ”„ Forwarding to Databricks Model Serving API...
âœ… SUCCESS abc12345
   Response length: 823 characters
   Response time: 2.34s
ğŸ“¤ RESPONSE abc12345
================================================================================
```

### In Databricks Notebook:

```
[1/5] (20.0%) | Elapsed: 0.5m | ETA: 2.0m | RFP: Q001
  âœ“ Complete (2.3s)
```

### After DEMO Mode (5 responses):

Check statistics:
```bash
curl http://localhost:8001/stats

# Returns:
{
  "total_requests": 15,        # 3 stages Ã— 5 responses
  "total_tokens": 8145,
  "average_response_time_seconds": 2.1
}
```

---

## ğŸ“ Files Guide

### Core Files (Use These)

| File | What It Does |
|------|-------------|
| `agl_rfp_dspy_with_mcp.py` | ğŸ““ Databricks notebook with DSPy + MCP integration |
| `local_mcp_server.py` | ğŸ”„ DSPy proxy server (run locally) |
| `start-dspy-proxy.sh` | ğŸš€ Easy startup script |

### Documentation (Read These)

| File | What It Explains |
|------|-----------------|
| `START_HERE.md` | ğŸ‘‰ This file - where to begin |
| `TWO_MCP_SERVERS_EXPLAINED.md` | ğŸ“š Explains your two MCP servers |
| `DSPY_MCP_INTEGRATION_GUIDE.md` | ğŸ”§ Technical deep dive |
| `MCP_DOCKER_SETUP_GUIDE.md` | ğŸ³ Docker setup options |

### Optional Files

| File | What It's For |
|------|--------------|
| `Dockerfile.dspy-proxy` | ğŸ³ Docker image for proxy (optional) |
| `docker-compose-mcp.yml` | ğŸ³ Docker Compose setup (optional) |

---

## ğŸ“ Understanding the Flow

```
Databricks Notebook (agl_rfp_dspy_with_mcp.py)
    â†“
DSPy Refinement Agent
    â†“ (3 stages per response)
MCPServerLM (custom LM class)
    â†“
Your Local MCP Server (localhost:8001)
    â†“ (via ngrok)
Databricks Model Serving API
    â†“
Claude Sonnet 4.5
    â†“
Response flows back through MCP
    â†“
DSPy receives refined text
```

**For 200 responses:**
- 3 stages Ã— 200 responses = **600 API calls** through your MCP server
- Estimated time: **100-200 minutes**
- Cost: **~$2.70** (same as direct API)

---

## âœ… Checklist

Before running batch refinement:

- [ ] Databricks Docs MCP is running in Docker (check: `docker ps | grep databricks-mcp-server`)
- [ ] Started DSPy Proxy MCP (`./start-dspy-proxy.sh`)
- [ ] Started ngrok (`ngrok http 8001`)
- [ ] Copied ngrok HTTPS URL
- [ ] Updated `MCP_SERVER_URL` in Databricks notebook
- [ ] Set `BATCH_MODE = "DEMO"` for testing
- [ ] Both terminals (proxy + ngrok) are open and running

---

## ğŸ› Troubleshooting

### "Connection refused" in Databricks

**Check:**
```bash
# Is proxy running?
curl http://localhost:8001/health

# Is ngrok running?
curl https://your-ngrok-url.ngrok.io/health
```

**Fix:** Make sure both terminals are still open and running.

### Port 8001 already in use

**Fix:**
```bash
# The start script will automatically use 8002 if 8001 is busy
./start-dspy-proxy.sh
```

### Want to see what's happening

**Monitor:**
```bash
# In the terminal where proxy is running, you'll see live logs

# Or check statistics
curl http://localhost:8001/stats
```

---

## ğŸ¯ After Testing (DEMO Mode)

Once DEMO mode works (5 responses):

1. âœ… **Verify results** in Databricks output
2. âœ… **Check MCP server logs** - did all 15 requests succeed?
3. âœ… **Review refined responses** for quality
4. âœ… **Switch to FULL mode:**
   ```python
   BATCH_MODE = "FULL"  # Process all 200 responses
   ```
5. âœ… **Run batch refinement** (~2-3 hours)
6. âœ… **Check final results** in Delta table

---

## ğŸ‰ What You Get

After setup:

âœ… **All DSPy calls** route through your MCP server
âœ… **Full visibility** - see every prompt and response
âœ… **Custom logging** - all requests stored locally
âœ… **Statistics** - track tokens, timing, success rate
âœ… **Same DSPy features** - ChainOfThought, Signatures, 3-stage pipeline
âœ… **Production-ready** - 200 RFP responses refined with AGL + Databricks context

---

## ğŸ“ Quick Commands Reference

```bash
# Start proxy
./start-dspy-proxy.sh

# Start ngrok
ngrok http 8001

# Check health
curl http://localhost:8001/health

# View statistics
curl http://localhost:8001/stats

# Check proxy logs (if running in Docker)
docker logs -f dspy-proxy

# Stop proxy (if running in Docker)
docker stop dspy-proxy
```

---

## ğŸš¦ Status Check

Run these to verify everything is working:

```bash
# 1. Check Databricks Docs MCP (existing)
docker ps | grep databricks-mcp-server
# Should show running container

# 2. Check DSPy Proxy MCP (new)
curl http://localhost:8001/health
# Should return: {"status":"healthy",...}

# 3. Check ngrok
curl https://your-ngrok-url.ngrok.io/health
# Should return: {"status":"healthy",...}

# All three working? You're ready to go! ğŸ‰
```

---

## ğŸ“ Remember

- **Databricks Docs MCP** (Docker) = For Claude Code documentation searches
- **DSPy Proxy MCP** (Local) = For DSPy batch API proxying
- They're **independent** and both can run simultaneously
- Your **existing MCP config** stays unchanged

---

## Next Step

**Read:** [`TWO_MCP_SERVERS_EXPLAINED.md`](TWO_MCP_SERVERS_EXPLAINED.md)

Then follow the Quick Start above! ğŸš€

---

**Created:** 2026-01-18
**Purpose:** Clear starting point for DSPy batch refinement with MCP integration
**Time to setup:** ~5 minutes
**Time for 200 responses:** ~2-3 hours
